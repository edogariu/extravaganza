{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1fce2e",
   "metadata": {},
   "source": [
    "# Testing LQR, H_inf, GPC, BPC Controllers with  Lifter\n",
    "The entire reason we were interested in neural nets with this property is to ensure that minimizing state norm of the lifted state corresponds to minimizing norm of the inputs!. Lifters with this property technically form an LDS with quadratic costs, lending themselves to provable control via LQR (optimal control, $H_{\\infty}$ (robust control), and perhaps even GPC (best of both worlds?)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f08784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created a temporary directory at /var/folders/5m/0xr906c130vdqvkm3g21n6wr0000gn/T/tmpw2nkspqq\n",
      "INFO: Writing /var/folders/5m/0xr906c130vdqvkm3g21n6wr0000gn/T/tmpw2nkspqq/_remote_module_non_scriptable.py\n",
      "INFO: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO: Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "INFO: Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)  # set level to INFO for wordy\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from extravaganza.dynamical_systems import LDS, Gym\n",
    "\n",
    "from extravaganza.observables import TimeDelayedObservation, FullObservation, Trajectory\n",
    "from extravaganza.sysid import Lifter, LiftedController\n",
    "from extravaganza.controllers import LQR, HINF, BPC, GPC, RBPC, EvanBPC, ConstantController\n",
    "from extravaganza.rescalers import ADAM, D_ADAM, DoWG, FIXED_RESCALE\n",
    "from extravaganza.stats import Stats\n",
    "from extravaganza.utils import ylim, render, append, opnorm, dare_gain, least_squares\n",
    "from extravaganza.experiments import Experiment\n",
    "\n",
    "# seeds for randomness. setting to `None` uses random seeds\n",
    "SYSTEM_SEED = None\n",
    "CONTROLLER_SEED = None\n",
    "SYSID_SEED = None\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# --------------------------    SYSTEM HYPERPARAMETERS    ------------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "reset_condition = lambda t: t % 200000 == 0  # how often to reset the system\n",
    "\n",
    "ds = 4\n",
    "du = 1\n",
    "initial_control = jnp.zeros(du)\n",
    "make_system = lambda : Gym('CartPoleContinuous-v1', \n",
    "                           repeat=3,\n",
    "                           use_reward_costs=False, send_done=False, max_episode_len=600, seed=SYSTEM_SEED,\n",
    "                          render=False)\n",
    "\n",
    "# observable = TimeDelayedObservation(hh=2, control_dim=du, state_dim=ds, time_embedding_dim=8,\n",
    "#                                     use_states=True, use_costs=True, use_controls=True, use_time=False)\n",
    "observable = FullObservation(ds)\n",
    "ds = observable.obs_dim\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fb0839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: (PC3): decoder not provided, so reconstruction error will NOT be computed\n",
      "INFO: (PC3): contrastive predictive coding will NOT be computed\n",
      "/Users/evandigiorno/Desktop/extravaganza/env/lib/python3.10/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/20000 [00:00<?, ?it/s]INFO: (EXPERIMENT): reset!\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:24<00:00, 802.11it/s]\n",
      "INFO: (LIFTER): ending sysid phase at step 20000\n",
      "INFO: training!\n",
      "INFO: mean loss for epochs -25 - 0:\n",
      "INFO: \t\tl2 linearization: 0.00013526459224522114\n",
      "INFO: \t\tsimplification: 0.00639486238360405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: mean loss for epochs 0 - 25:\n",
      "INFO: \t\tl2 linearization: 0.0005205188132822513\n",
      "INFO: \t\tsimplification: 0.0011425607576966287\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T0 = 20000\n",
    "\n",
    "sysid_args = {\n",
    "    'obs_dim': ds,\n",
    "    'control_dim': du,\n",
    "\n",
    "    'max_traj_len': int(1e6),\n",
    "    'exploration_scales': 0.75,\n",
    "    'exploration_bounds': (-1., 1.),\n",
    "\n",
    "    'depth': 4,\n",
    "    'sigma': 0,\n",
    "    'determinstic_encoder': True,\n",
    "    'num_epochs': 500,\n",
    "    'lifter_lr': 0.001,                                                           \n",
    "\n",
    "    'seed': SYSID_SEED,\n",
    "}\n",
    "\n",
    "sysids = {\n",
    "#     'Linear': Lifter(method='identity', state_dim=ds, **sysid_args),\n",
    "#     'Koopman': Lifter(method='fourier', state_dim=121, **sysid_args),\n",
    "    'Lifted': Lifter(method='nn', state_dim=24, **sysid_args),\n",
    "}\n",
    "\n",
    "for k, sysid in sysids.items():  # interact in order to perform sysid\n",
    "    # make system and get initial control\n",
    "    system = make_system()\n",
    "    control = initial_control\n",
    "    print(k)\n",
    "    traj = Trajectory()\n",
    "    for t in tqdm.trange(T0):\n",
    "        if t == 0 or reset_condition(t):\n",
    "            logging.info('(EXPERIMENT): reset!')\n",
    "            system.reset(None)\n",
    "            sysid.end_trajectory()\n",
    "            traj = Trajectory()\n",
    "            pass\n",
    "\n",
    "        cost, state = system.interact(control)  # state will be `None` for unobservable systems\n",
    "        traj.add_state(cost, state)\n",
    "        obs = observable(traj)\n",
    "        control = sysid.explore(cost, obs) + initial_control\n",
    "        traj.add_control(control)\n",
    "\n",
    "        if (isinstance(state, jnp.ndarray) and jnp.any(jnp.isnan(state))) or (cost > 1e20):\n",
    "            logging.error('(EXPERIMENT): state {} or cost {} diverged'.format(state, cost))\n",
    "            assert False\n",
    "\n",
    "    sysid.end_exploration(wordy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8c730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------\n",
    "# ------------------------    EXPERIMENT HYPERPARAMETERS    ----------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "num_trials = 1\n",
    "T = 2000  # total timesteps\n",
    "use_multiprocessing = False\n",
    "render_every = None\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ------------------------    LIFT/SYSID HYPERPARAMETERS    ----------------------------\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "controllers_to_test = {\n",
    "#     'LQR': LQR,\n",
    "#     'HINF': HINF,\n",
    "#     'GPC': GPC,\n",
    "# #     'BPC': BPC,\n",
    "#     'RBPC': RBPC,\n",
    "    'EvanBPC': EvanBPC,\n",
    "}\n",
    "\n",
    "h = 10  # controller memory length (# of w's to use on inference)\n",
    "m_update_rescaler = lambda : ADAM(0.001, betas=(0.9, 0.999), use_bias_correction=True)\n",
    "m0_update_rescaler = lambda : ADAM(0.00, betas=(0.9, 0.999), use_bias_correction=True)\n",
    "k_update_rescaler = lambda : ADAM(0.00, betas=(0.9, 0.999), use_bias_correction=True)\n",
    "# m_update_rescaler = lambda : FIXED_RESCALE(alpha=0.001)\n",
    "# k_update_rescaler = lambda : FIXED_RESCALE(alpha=0.001)\n",
    "evan_bpc_args = {\n",
    "    'h': h,  \n",
    "    'method': 'REINFORCE',\n",
    "    'initial_scales': (0, 0.01, 0),  # M, M0, K   (uses M0's scale for REINFORCE)\n",
    "    'rescalers': (m_update_rescaler, m0_update_rescaler, k_update_rescaler),\n",
    "    'bounds': None,\n",
    "    'initial_u': jnp.zeros(du),\n",
    "    'decay_scales': False,\n",
    "    'use_tanh': False,\n",
    "    'use_stabilizing_K': False,\n",
    "}\n",
    "\n",
    "make_controllers = {'0': lambda sys: ConstantController(jnp.zeros(du), ds)}\n",
    "for k, sysid in sysids.items(): \n",
    "    make_controllers.update({k + ' ' + controller_k: lambda sys: LiftedController(v(A=sysid.A, B=sysid.B, seed=CONTROLLER_SEED) if controller_k != 'EvanBPC' else v(A=sysid.A, B=sysid.B, seed=CONTROLLER_SEED, **evan_bpc_args), lifter=sysid) for controller_k, v in controllers_to_test.items()})\n",
    "    \n",
    "experiment_args = {\n",
    "    'make_system': make_system,\n",
    "    'make_controllers': make_controllers,\n",
    "    'num_trials': num_trials,\n",
    "    'observable': observable,\n",
    "    'T': T, \n",
    "    'reset_condition': reset_condition,\n",
    "    'reset_seed': SYSTEM_SEED,\n",
    "    'use_multiprocessing': use_multiprocessing,\n",
    "    'render_every': render_every,\n",
    "}   \n",
    "\n",
    "dut_experiment = Experiment('lifting_research_dut')\n",
    "dut_experiment(**experiment_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(experiment: Experiment):\n",
    "    assert experiment.stats is not None, 'cannot plot the results of an experiment that hasnt been run'\n",
    "    all_stats = experiment.stats\n",
    "    \n",
    "    # clear plot and calc nrows\n",
    "    plt.clf()\n",
    "    n = 3\n",
    "    nrows = n + (len(all_stats) + 1) // 2\n",
    "    fig, ax = plt.subplots(nrows, 2, figsize=(16, 6 * nrows))\n",
    "\n",
    "    # plot stats\n",
    "    for i, (method, stats) in enumerate(all_stats.items()):\n",
    "        if stats is None: \n",
    "            logging.warning('{} had no stats'.format(method))\n",
    "            continue\n",
    "            \n",
    "        stats.plot(ax[0, 0], 'true states', label=method, plot_idx=2)\n",
    "        stats.plot(ax[1, 0], 'costs', label=method)\n",
    "        stats.plot(ax[1, 1], 'costs', label=method, plot_cummean=True)\n",
    "        \n",
    "        stats.plot(ax[2, 0], 'states', label=method, plot_norm=True)  # norm of the \"state\"\n",
    "        from extravaganza.sysid import LOSS_WEIGHTS\n",
    "        for k in LOSS_WEIGHTS.keys(): stats.plot(ax[2, 1], k, label=k)  # various nn losses\n",
    "            \n",
    "        i_ax = ax[n + i // 2, i % 2]\n",
    "        stats.plot(ax[0, 1], 'disturbances', label=method, plot_norm=True)\n",
    "        stats.plot(i_ax, '-K @ state', label='-K @ state', plot_idx=0)\n",
    "        stats.plot(i_ax, 'M \\cdot w', label='M \\cdot w', plot_idx=0)\n",
    "        stats.plot(i_ax, 'M0', label='M0', plot_idx=0)\n",
    "        i_ax.set_title('u decomp for {}'.format(method))\n",
    "        i_ax.legend()\n",
    "\n",
    "    # set titles and legends and limits and such\n",
    "    # (note: `ylim()` is so useful! because sometimes one thing blows up and then autoscale messes up all plots)\n",
    "    _ax = ax[0, 0]; _ax.set_title('true states'); _ax.legend()\n",
    "    _ax = ax[0, 1]; _ax.set_title('disturbances'); _ax.legend()\n",
    "    _ax = ax[1, 0]; _ax.set_title('instantaneous costs'); _ax.legend()\n",
    "    _ax = ax[1, 1]; _ax.set_title('avg costs'); _ax.legend(); ylim(_ax, 0, 10)\n",
    "    _ax = ax[2, 0]; _ax.set_title('reconstructed states'); _ax.legend()\n",
    "    _ax = ax[2, 1]; _ax.set_title('nn losses'); _ax.legend()  \n",
    "    pass\n",
    "plot(dut_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a4e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extravaganza",
   "language": "python",
   "name": "extravaganza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
