{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1b0fb6",
   "metadata": {},
   "source": [
    "# Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29db997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)  # set level to INFO for wordy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import torch.optim as optim\n",
    "\n",
    "from extravaganza.dynamical_systems import LinearRegression, MNIST\n",
    "\n",
    "from extravaganza.observables import Observable, TimeDelayedObservation, FullObservation, Trajectory\n",
    "from extravaganza.sysid import Lifter, LiftedController, OfflineSysid\n",
    "from extravaganza.controllers import LQR, HINF, BPC, GPC, RBPC, EvanBPC, ConstantController\n",
    "from extravaganza.rescalers import ADAM, D_ADAM, DoWG, FIXED_RESCALE\n",
    "from extravaganza.stats import Stats\n",
    "from extravaganza.utils import ylim, render, append, opnorm, dare_gain, least_squares\n",
    "from extravaganza.experiments import Experiment\n",
    "\n",
    "# seeds for randomness. setting to `None` uses random seeds\n",
    "SYSTEM_SEED = None\n",
    "CONTROLLER_SEED = None\n",
    "SYSID_SEED = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f06917",
   "metadata": {},
   "source": [
    "## System\n",
    "Here, we tune the parameters of a gradient descent algorithm training a neural network. We can train either a linear regression or an MLP or CNN MNIST model. Any optimizer can be used, such as `SGD` or `Adam`, and any parameter can be tuned, such as `lr` or `momentum`. \n",
    "\n",
    "Which optimizer to use is specified in the `make_optimizer` argument, and how to update and tune things is specified in the `apply_control` argument.\n",
    "\n",
    "At the moment, we apply a 2-dimensional control $u = (u_0, u_1)$ that dictates 2 parameters of the learning rate schedule, given as\n",
    "$$\\eta_t := \\frac{u_0}{1 + u_1 \\cdot \\sqrt{t}},$$\n",
    "where $u_0$ is the initial learning rate and $u_1$ is a decay rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c16dbd",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2127356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'nn'\n",
    "filename = '../logs/{}.pkl'.format(name)\n",
    "\n",
    "def get_experiment_args():\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # ------------------------    EXPERIMENT HYPERPARAMETERS    ----------------------------\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    num_trials = 1\n",
    "    T = 2000  # total timesteps\n",
    "    T0 = 1000  # number of timesteps to just sysid for our methods\n",
    "    reset_condition = lambda t: t % 20 == 0  # when to reset the system (which means fresh LR/MNIST model params)\n",
    "    use_multiprocessing = False  # unsure if this works in jupyter notebooks\n",
    "    render_every = None\n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # --------------------------    SYSTEM HYPERPARAMETERS    ------------------------------\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    initial_lr = 0.1\n",
    "    initial_decay = 0.8\n",
    "    initial_control = jnp.array([initial_lr, initial_decay])\n",
    "    du = initial_control.shape[0]\n",
    "    \n",
    "    make_optimizer = lambda model: optim.SGD(model.parameters(), lr=initial_lr)\n",
    "    def apply_control(control, system): system.opt.param_groups[0]['lr'] = max(0, control[0].item()) / (1 + max(0., control[1].item()) * system.episode_t ** 0.5)\n",
    "\n",
    "    make_system = lambda : LinearRegression(make_optimizer, apply_control,\n",
    "                                            dataset = 'generated', \n",
    "                                            repeat = 20,\n",
    "                                            eval_every = 1, seed=SYSTEM_SEED)   \n",
    "\n",
    "#     make_system = lambda : MNIST(make_optimizer, apply_control,\n",
    "#                                  model_type = 'MLP', batch_size = 64,\n",
    "#                                  repeat = 5,\n",
    "#                                  eval_every=None, seed=SYSTEM_SEED)   # best is something like (0.5, 0.05) or (0.2, 0)\n",
    "\n",
    "    hh = 3\n",
    "    observable = TimeDelayedObservation(hh = hh, control_dim=du, time_embedding_dim=8,\n",
    "                                        use_states=False, use_cost_diffs=False,\n",
    "                                        use_costs=True, use_controls=True, use_time=True)\n",
    "    do = observable.obs_dim  # dimension of observations to lift from\n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # ------------------------    LIFT/SYSID HYPERPARAMETERS    ----------------------------\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    dl = 4  # dimension of state to lift to\n",
    "\n",
    "    bounds = [(0, 1), (0, 1)]\n",
    "    exploration_args = {'scales': 0.1, 'bounds': bounds, 'avg_len': 3,}\n",
    "    sysid_args = {\n",
    "        'obs_dim': do,\n",
    "        'control_dim': du,\n",
    "\n",
    "        'exploration_args': {'random 1.0': exploration_args,\n",
    "    #                          'impulse 0.25': exploration_args,\n",
    "                            },\n",
    "\n",
    "        'method': 'nn',\n",
    "        'AB_method': 'regression',\n",
    "        'deterministic': False,\n",
    "        'isometric': True,\n",
    "        \n",
    "        'sigma': 0,\n",
    "        'depth': 8,\n",
    "        'num_iters': 16000,\n",
    "        'batch_size': 256,\n",
    "        'lifter_lr': 0.001,\n",
    "        'hh': hh,\n",
    "        'initial_control': initial_control,\n",
    "\n",
    "        'seed': SYSID_SEED,\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # ------------------------    CONTROLLER HYPERPARAMETERS    ----------------------------\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    h = 5 # controller memory length (# of w's to use on inference)\n",
    "    m_update_rescaler = lambda : ADAM(alpha=0.00, betas=(0.9, 0.999), use_bias_correction=True)\n",
    "    m0_update_rescaler = lambda : ADAM(alpha=0.004, betas=(0.9, 0.999), use_bias_correction=True)\n",
    "    k_update_rescaler = lambda : ADAM(alpha=0.004, betas=(0.9, 0.999), use_bias_correction=True)\n",
    "#     m_update_rescaler = lambda : FIXED_RESCALE(alpha=0.0)\n",
    "#     m0_update_rescaler = lambda : FIXED_RESCALE(alpha=0.01)\n",
    "#     k_update_rescaler = lambda : FIXED_RESCALE(alpha=0.0)\n",
    "\n",
    "    nonlinear_bpc_args = {\n",
    "        'h': h,  \n",
    "        'method': 'REINFORCE',\n",
    "        'initial_scales': (0, 0.01, 0),  # M, M0, K   (uses M0's scale for REINFORCE)\n",
    "        'rescalers': (m_update_rescaler, m0_update_rescaler, k_update_rescaler),\n",
    "#         'bounds': bounds,\n",
    "        'initial_u': jnp.zeros(du),\n",
    "        'decay_scales': False,\n",
    "        'use_tanh': False,\n",
    "        'use_stabilizing_K': True,\n",
    "        'seed': CONTROLLER_SEED\n",
    "    }\n",
    "    \n",
    "    # this is a bit of a mess at the minute, but here goes: \n",
    "    #         - `OfflineSysid` is a wrapper to do sysid phase followed by control,\n",
    "    #         - `LiftedController` is a wrapper that lifts states before passing to the controller, and \n",
    "    #         - `EvanBPC` is the controller (can be replaced with `extravaganza.controllers.RBPC` as well)\n",
    "    # I currently use lambdas as object generators to make them from scratch easily, but soon i will switch to actual\n",
    "    # generators or using deepcopies or something :)\n",
    "    \n",
    "    make_controllers = {\n",
    "#         '{}/{}'.format(*[round(v.item(), 2) for v in initial_control]): lambda sys: ConstantController(initial_control, do),\n",
    "#         #         'Lifted LQR': lambda sys: OfflineSysid(lambda sysid: LiftedController(controller=LQR(sysid.A, sysid.B), lifter=sysid),\n",
    "#                                           sysid=Lifter(state_dim=dl, **sysid_args), T0=T0),\n",
    "#         'Lifted HINF': lambda sys: OfflineSysid(lambda sysid: LiftedController(controller=HINF(sysid.A, sysid.B), lifter=sysid),\n",
    "#                                           sysid=Lifter(state_dim=dl, **sysid_args), T0=T0),\n",
    "#         'Lifted GPC': lambda sys: OfflineSysid(lambda sysid: LiftedController(controller=GPC(sysid.A, sysid.B, decay=False, lr_scale=0.01, H=10), lifter=sysid),\n",
    "#                                           sysid=Lifter(state_dim=dl, **sysid_args), T0=T0),\n",
    "        'Lifted EvanBPC': lambda sys: OfflineSysid(lambda sysid: LiftedController(controller=EvanBPC(sysid.A, sysid.B, **nonlinear_bpc_args), lifter=sysid),\n",
    "                                          sysid=Lifter(state_dim=dl, **sysid_args), T0=T0)\n",
    "    }\n",
    "    experiment_args = {    \n",
    "        'make_system': make_system,\n",
    "        'make_controllers': make_controllers,\n",
    "        'observable': observable,\n",
    "        'num_trials': num_trials,\n",
    "        'T': T,\n",
    "        'reset_condition': reset_condition,\n",
    "        'reset_seed': None,\n",
    "        'use_multiprocessing': use_multiprocessing,\n",
    "        'render_every': render_every,\n",
    "    }\n",
    "    return experiment_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd3a0d",
   "metadata": {},
   "source": [
    "## actually run the thing :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c78c6b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: (EXPERIMENT) --------------------------------------------------\n",
      "INFO: (EXPERIMENT) ----------------- TRIAL 0 -----------------------\n",
      "INFO: (EXPERIMENT) --------------------------------------------------\n",
      "\n",
      "INFO: (EXPERIMENT): testing Lifted EvanBPC\n",
      "INFO: (EXPLORER) generating exploration control sequences using ['random'] w.p. [1.]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:10<00:00, 494.84it/s]\n",
      "INFO: (LIFTER): we will be linearizing in latent dimension 9 and linearly project down to embedding dimension 4\n",
      "INFO: (LIFTER): we are imposing simplification as a hard constraint on the latent space via isometric NN\n",
      "INFO: (LIFTER): using \"regression\" method to get the AB matrices during each training step\n",
      "  0%|                                                                                                                       | 0/2000 [00:00<?, ?it/s]INFO: (EXPERIMENT): reset at t=0!\n",
      "  1%|▋                                                              | 20/2000 [00:01<02:14, 14.76it/s, control=[0.07035641 0.7409986 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=20!\n",
      "  2%|█▎                                                             | 40/2000 [00:02<02:19, 14.00it/s, control=[0.09403685 0.9095558 ], cost=0.00923]INFO: (EXPERIMENT): reset at t=40!\n",
      "  3%|█▉                                                             | 60/2000 [00:03<01:56, 16.66it/s, control=[0.19295795 0.7877802 ], cost=0.00924]INFO: (EXPERIMENT): reset at t=60!\n",
      "  4%|██▌                                                            | 80/2000 [00:05<01:58, 16.22it/s, control=[0.30846485 0.86168116], cost=0.00921]INFO: (EXPERIMENT): reset at t=80!\n",
      "  5%|███                                                           | 100/2000 [00:06<02:00, 15.70it/s, control=[0.11088444 0.8711023 ], cost=0.00923]INFO: (EXPERIMENT): reset at t=100!\n",
      "  6%|███▋                                                          | 120/2000 [00:07<02:12, 14.17it/s, control=[0.15204243 0.9228507 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=120!\n",
      "  7%|████▎                                                         | 140/2000 [00:08<01:51, 16.62it/s, control=[0.01982551 0.9452039 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=140!\n",
      "  8%|████▉                                                         | 160/2000 [00:10<01:52, 16.30it/s, control=[0.10233237 0.95267177], cost=0.00921]INFO: (EXPERIMENT): reset at t=160!\n",
      "  9%|█████▌                                                        | 180/2000 [00:11<01:52, 16.17it/s, control=[0.15892032 0.94503665], cost=0.00921]INFO: (EXPERIMENT): reset at t=180!\n",
      " 10%|██████▍                                                         | 200/2000 [00:13<02:03, 14.55it/s, control=[0.2547911 0.7603867], cost=0.00922]INFO: (EXPERIMENT): reset at t=200!\n",
      " 11%|██████▊                                                       | 220/2000 [00:14<02:07, 13.93it/s, control=[0.17419216 0.7084932 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=220!\n",
      " 12%|███████▍                                                      | 240/2000 [00:15<01:47, 16.37it/s, control=[0.03060497 0.8233361 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=240!\n",
      " 13%|████████▎                                                       | 260/2000 [00:16<01:48, 16.05it/s, control=[0.        0.5973827], cost=0.00921]INFO: (EXPERIMENT): reset at t=260!\n",
      " 14%|████████▋                                                     | 280/2000 [00:18<01:50, 15.50it/s, control=[0.01111117 0.97080356], cost=0.00922]INFO: (EXPERIMENT): reset at t=280!\n",
      " 15%|█████████▍                                                     | 300/2000 [00:19<02:02, 13.87it/s, control=[0.         0.78252286], cost=0.0279]INFO: (EXPERIMENT): reset at t=300!\n",
      " 16%|█████████▉                                                    | 320/2000 [00:20<01:44, 16.01it/s, control=[0.18921754 0.7733001 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=320!\n",
      " 17%|██████████▌                                                   | 340/2000 [00:22<01:39, 16.64it/s, control=[0.18511957 0.47315848], cost=0.00921]INFO: (EXPERIMENT): reset at t=340!\n",
      " 18%|███████████▏                                                  | 360/2000 [00:23<01:40, 16.37it/s, control=[0.00692874 0.8529944 ], cost=0.00922]INFO: (EXPERIMENT): reset at t=360!\n",
      " 19%|███████████▊                                                  | 380/2000 [00:24<01:52, 14.44it/s, control=[0.04092028 0.79958683], cost=0.00924]INFO: (EXPERIMENT): reset at t=380!\n",
      " 20%|████████████▍                                                 | 400/2000 [00:26<01:52, 14.29it/s, control=[0.39892015 0.7349409 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=400!\n",
      " 21%|█████████████                                                 | 420/2000 [00:27<01:37, 16.20it/s, control=[0.21110365 0.70193756], cost=0.00921]INFO: (EXPERIMENT): reset at t=420!\n",
      " 22%|█████████████▋                                                | 440/2000 [00:28<01:37, 15.99it/s, control=[0.         0.82973164], cost=0.00921]INFO: (EXPERIMENT): reset at t=440!\n",
      " 23%|██████████████▎                                               | 460/2000 [00:29<01:45, 14.58it/s, control=[0.18091437 0.78849906], cost=0.00927]INFO: (EXPERIMENT): reset at t=460!\n",
      " 24%|██████████████▉                                               | 480/2000 [00:31<01:45, 14.43it/s, control=[0.09411543 0.7229301 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=480!\n",
      " 25%|████████████████                                                | 500/2000 [00:32<01:29, 16.80it/s, control=[0.3781585 0.8135323], cost=0.00921]INFO: (EXPERIMENT): reset at t=500!\n",
      " 26%|████████████████▋                                               | 520/2000 [00:33<01:30, 16.26it/s, control=[0.        0.8604195], cost=0.00922]INFO: (EXPERIMENT): reset at t=520!\n",
      " 27%|█████████████████▊                                                | 540/2000 [00:35<01:30, 16.07it/s, control=[0.       0.767811], cost=0.00948]INFO: (EXPERIMENT): reset at t=540!\n",
      " 28%|█████████████████▋                                             | 560/2000 [00:36<01:32, 15.53it/s, control=[0.         0.83832955], cost=0.0096]INFO: (EXPERIMENT): reset at t=560!\n",
      " 29%|█████████████████▉                                            | 580/2000 [00:37<01:41, 13.99it/s, control=[0.12646058 0.73464257], cost=0.00954]INFO: (EXPERIMENT): reset at t=580!\n",
      " 30%|██████████████████▌                                           | 600/2000 [00:39<01:25, 16.45it/s, control=[0.05937932 0.7741371 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=600!\n",
      " 31%|███████████████████▏                                          | 620/2000 [00:40<01:25, 16.12it/s, control=[0.09282242 0.77129924], cost=0.00922]INFO: (EXPERIMENT): reset at t=620!\n",
      " 32%|████████████████████▍                                           | 640/2000 [00:41<01:27, 15.62it/s, control=[0.        0.8313155], cost=0.00921]INFO: (EXPERIMENT): reset at t=640!\n",
      " 33%|████████████████████▍                                         | 660/2000 [00:43<01:30, 14.78it/s, control=[0.0584238  0.75144607], cost=0.00981]INFO: (EXPERIMENT): reset at t=660!\n",
      " 34%|█████████████████████                                         | 680/2000 [00:44<01:18, 16.81it/s, control=[0.         0.67571026], cost=0.00923]INFO: (EXPERIMENT): reset at t=680!\n",
      " 35%|██████████████████████▍                                         | 700/2000 [00:45<01:18, 16.62it/s, control=[0.2734321 0.852452 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=700!\n",
      " 36%|██████████████████████▎                                       | 720/2000 [00:46<01:19, 16.16it/s, control=[0.24860457 1.        ], cost=0.00921]INFO: (EXPERIMENT): reset at t=720!\n",
      " 37%|███████████████████████▋                                        | 740/2000 [00:48<01:20, 15.56it/s, control=[0.0671484 0.7496371], cost=0.00921]INFO: (EXPERIMENT): reset at t=740!\n",
      " 38%|███████████████████████▌                                      | 760/2000 [00:49<01:27, 14.19it/s, control=[0.06929682 0.67319435], cost=0.00929]INFO: (EXPERIMENT): reset at t=760!\n",
      " 39%|████████████████████████▏                                     | 780/2000 [00:50<01:12, 16.79it/s, control=[0.         0.98048705], cost=0.00921]INFO: (EXPERIMENT): reset at t=780!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████▏                                     | 800/2000 [00:51<01:14, 16.08it/s, control=[0.15492101 0.661502  ], cost=0.0886]INFO: (EXPERIMENT): reset at t=800!\n",
      " 41%|█████████████████████████▍                                    | 820/2000 [00:53<01:15, 15.69it/s, control=[0.16999403 0.8429009 ], cost=0.00921]INFO: (EXPERIMENT): reset at t=820!\n",
      " 42%|██████████████████████████                                    | 840/2000 [00:54<01:22, 14.14it/s, control=[0.09977766 0.88834006], cost=0.00921]INFO: (EXPERIMENT): reset at t=840!\n",
      " 43%|██████████████████████████▋                                   | 860/2000 [00:55<01:07, 16.94it/s, control=[0.         0.94923395], cost=0.00921]INFO: (EXPERIMENT): reset at t=860!\n",
      " 44%|███████████████████████████▎                                  | 880/2000 [00:57<01:07, 16.61it/s, control=[0.         0.82991743], cost=0.00921]INFO: (EXPERIMENT): reset at t=880!\n",
      " 45%|████████████████████████████▎                                  | 900/2000 [00:58<01:07, 16.18it/s, control=[0.15044518 0.56451744], cost=0.0447]INFO: (EXPERIMENT): reset at t=900!\n",
      " 46%|█████████████████████████████▍                                  | 920/2000 [00:59<01:12, 14.99it/s, control=[0.295717  0.7694488], cost=0.00921]INFO: (EXPERIMENT): reset at t=920!\n",
      " 47%|█████████████████████████████▏                                | 940/2000 [01:00<01:15, 14.09it/s, control=[0.06226093 0.82784   ], cost=0.00921]INFO: (EXPERIMENT): reset at t=940!\n",
      " 48%|█████████████████████████████▊                                | 960/2000 [01:02<01:02, 16.60it/s, control=[0.10722772 0.6216611 ], cost=0.00922]INFO: (EXPERIMENT): reset at t=960!\n",
      " 49%|██████████████████████████████▍                               | 980/2000 [01:03<01:02, 16.32it/s, control=[0.10537308 0.89714444], cost=0.00921]INFO: (EXPERIMENT): reset at t=980!\n",
      " 50%|██████████████████████████████▉                               | 998/2000 [01:04<01:10, 14.22it/s, control=[0.1645337  0.88867414], cost=0.00921]INFO: (SYSID WRAPPER) ending exploration at timestep 1000\n",
      "INFO: (LIFTER): ending sysid phase at step 999\n",
      "INFO: (LIFTER): NOTE THAT WE ARE USING FMEAN TO RESCALE EMBEDDINGS DURING INFERENCE (so outputs of `get_state()` will have their true norms instead of their normalized ones)!!!\n",
      "INFO: training!\n",
      "INFO: mean loss for iters -1600 - 0:\n",
      "INFO: \t\tl2 linearization 0: \t0.000864880857989192\n",
      "INFO: \t\tl2 linearization 1: \t0.0020188160706311464\n",
      "INFO: \t\tl2 linearization 2: \t0.001558249699883163\n",
      "INFO: \t\tnontrivial: \t0.42098331451416016\n",
      "INFO: \t\tproj_error: \t0.13597877323627472\n",
      "INFO: \t\tproj_isometry: \t2.922362804412842\n",
      "INFO: \t\tsimplification: \t0.0002201735769631341\n",
      "INFO: \t\tsimplification 0: \t0.00010628653399180621\n",
      "INFO: \t\tsimplification 1: \t0.0002170576190110296\n",
      "INFO: \t\tsimplification 2: \t2.5102975996560417e-05\n",
      "INFO: mean loss for iters 0 - 1600:\n",
      "INFO: \t\tl2 linearization 0: \t0.015970981014008886\n",
      "INFO: \t\tl2 linearization 1: \t0.021416750126027184\n",
      "INFO: \t\tl2 linearization 2: \t0.024739910110832854\n",
      "INFO: \t\tnontrivial: \t1.1945923842524644\n",
      "INFO: \t\tproj_error: \t0.13473080060182838\n",
      "INFO: \t\tproj_isometry: \t2.5681995598971845\n",
      "INFO: \t\tsimplification: \t2.178197759077945\n",
      "INFO: \t\tsimplification 0: \t1.205471920859481\n",
      "INFO: \t\tsimplification 1: \t1.7189724203660592\n",
      "INFO: \t\tsimplification 2: \t2.154546429735178\n",
      "INFO: mean loss for iters 1600 - 3200:\n",
      "INFO: \t\tl2 linearization 0: \t0.018230204810853367\n",
      "INFO: \t\tl2 linearization 1: \t0.029522467664493207\n",
      "INFO: \t\tl2 linearization 2: \t0.03400349903941105\n",
      "INFO: \t\tnontrivial: \t2.945725349348795\n",
      "INFO: \t\tproj_error: \t0.13816756538435584\n",
      "INFO: \t\tproj_isometry: \t2.3178640200197695\n",
      "INFO: \t\tsimplification: \t4.559849830492742\n",
      "INFO: \t\tsimplification 0: \t1.6270105066317684\n",
      "INFO: \t\tsimplification 1: \t1.8746711827830245\n",
      "INFO: \t\tsimplification 2: \t7.245061913125235\n",
      " 50%|██████████████████████████████▉                               | 998/2000 [01:22<01:10, 14.22it/s, control=[0.1645337  0.88867414], cost=0.00921]INFO: mean loss for iters 3200 - 4800:\n",
      "INFO: \t\tl2 linearization 0: \t0.01826833663927232\n",
      "INFO: \t\tl2 linearization 1: \t0.03126715014247566\n",
      "INFO: \t\tl2 linearization 2: \t0.03575137687213101\n",
      "INFO: \t\tnontrivial: \t1.8889948356442618\n",
      "INFO: \t\tproj_error: \t0.15703617081104312\n",
      "INFO: \t\tproj_isometry: \t2.202193592041731\n",
      "INFO: \t\tsimplification: \t3.286840340931825\n",
      "INFO: \t\tsimplification 0: \t2.3615006368303746\n",
      "INFO: \t\tsimplification 1: \t2.942292721256007\n",
      "INFO: \t\tsimplification 2: \t9.69801287582855\n",
      "INFO: mean loss for iters 4800 - 6400:\n",
      "INFO: \t\tl2 linearization 0: \t0.02093820123591513\n",
      "INFO: \t\tl2 linearization 1: \t0.030682951911019246\n",
      "INFO: \t\tl2 linearization 2: \t0.03441970581282021\n",
      "INFO: \t\tnontrivial: \t0.7791119764751057\n",
      "INFO: \t\tproj_error: \t0.16399785547779175\n",
      "INFO: \t\tproj_isometry: \t2.08670982003212\n",
      "INFO: \t\tsimplification: \t3.0726119945784207\n",
      "INFO: \t\tsimplification 0: \t1.6977976799210026\n",
      "INFO: \t\tsimplification 1: \t2.0722213888389036\n",
      "INFO: \t\tsimplification 2: \t3.0537483394455096\n",
      "INFO: mean loss for iters 6400 - 8000:\n",
      "INFO: \t\tl2 linearization 0: \t0.016087805377260338\n",
      "INFO: \t\tl2 linearization 1: \t0.02591725266786625\n",
      "INFO: \t\tl2 linearization 2: \t0.0311165294497755\n",
      "INFO: \t\tnontrivial: \t2.0163138376188\n",
      "INFO: \t\tproj_error: \t0.1428924676979659\n",
      "INFO: \t\tproj_isometry: \t2.0047957522422077\n",
      "INFO: \t\tsimplification: \t3.009795903796887\n",
      "INFO: \t\tsimplification 0: \t1.6287261409534823\n",
      "INFO: \t\tsimplification 1: \t2.626343844300463\n",
      "INFO: \t\tsimplification 2: \t6.585596511113708\n",
      "INFO: mean loss for iters 8000 - 9600:\n",
      "INFO: \t\tl2 linearization 0: \t0.017223665901695995\n",
      "INFO: \t\tl2 linearization 1: \t0.02779817597692727\n",
      "INFO: \t\tl2 linearization 2: \t0.03329694975719121\n",
      "INFO: \t\tnontrivial: \t1.6088007213175297\n",
      "INFO: \t\tproj_error: \t0.165689996638539\n",
      "INFO: \t\tproj_isometry: \t1.8410437967628241\n",
      "INFO: \t\tsimplification: \t3.027395163960713\n",
      "INFO: \t\tsimplification 0: \t1.6595030910860924\n",
      "INFO: \t\tsimplification 1: \t3.3675051276887302\n",
      "INFO: \t\tsimplification 2: \t15.17115884729268\n",
      "INFO: mean loss for iters 9600 - 11200:\n",
      "INFO: \t\tl2 linearization 0: \t0.01873600083248448\n",
      "INFO: \t\tl2 linearization 1: \t0.02605784241425681\n",
      "INFO: \t\tl2 linearization 2: \t0.029416521812572684\n",
      "INFO: \t\tnontrivial: \t1.7848064403430908\n",
      "INFO: \t\tproj_error: \t0.1531774287595181\n",
      "INFO: \t\tproj_isometry: \t1.746993426680565\n",
      "INFO: \t\tsimplification: \t3.0636160495609603\n",
      "INFO: \t\tsimplification 0: \t1.4525313612197044\n",
      "INFO: \t\tsimplification 1: \t2.005779383794341\n",
      "INFO: \t\tsimplification 2: \t5.87173163672222\n",
      "INFO: mean loss for iters 11200 - 12800:\n",
      "INFO: \t\tl2 linearization 0: \t0.015260493473583665\n",
      "INFO: \t\tl2 linearization 1: \t0.020638085533639695\n",
      "INFO: \t\tl2 linearization 2: \t0.022699030681942532\n",
      "INFO: \t\tnontrivial: \t1.6317869543930283\n",
      "INFO: \t\tproj_error: \t0.13310384564189007\n",
      "INFO: \t\tproj_isometry: \t1.6715004009008407\n",
      "INFO: \t\tsimplification: \t1.4651523586315636\n",
      "INFO: \t\tsimplification 0: \t1.3282663558012207\n",
      "INFO: \t\tsimplification 1: \t1.8798090546780566\n",
      "INFO: \t\tsimplification 2: \t2.565713380208186\n",
      "INFO: mean loss for iters 12800 - 14400:\n",
      "INFO: \t\tl2 linearization 0: \t0.02034395128866777\n",
      "INFO: \t\tl2 linearization 1: \t0.028817162940150638\n",
      "INFO: \t\tl2 linearization 2: \t0.037436313959215116\n",
      "INFO: \t\tnontrivial: \t1.0429817277006805\n",
      "INFO: \t\tproj_error: \t0.1546514680684777\n",
      "INFO: \t\tproj_isometry: \t1.5623762745410203\n",
      "INFO: \t\tsimplification: \t3.03781842571714\n",
      "INFO: \t\tsimplification 0: \t1.7079437817615493\n",
      "INFO: \t\tsimplification 1: \t3.3978866545190054\n",
      "INFO: \t\tsimplification 2: \t12.802806009699994\n",
      "INFO: mean loss for iters 14399 - 15999:\n",
      "INFO: \t\tl2 linearization 0: \t0.013857420981219093\n",
      "INFO: \t\tl2 linearization 1: \t0.02261728781589227\n",
      "INFO: \t\tl2 linearization 2: \t0.026609291935847067\n",
      "INFO: \t\tnontrivial: \t1.7133386592124589\n",
      "INFO: \t\tproj_error: \t0.11012021256261505\n",
      "INFO: \t\tproj_isometry: \t1.4799081691354514\n",
      "INFO: \t\tsimplification: \t1.7299666815309167\n",
      "INFO: \t\tsimplification 0: \t1.4231288530943806\n",
      "INFO: \t\tsimplification 1: \t2.450048924471327\n",
      "INFO: \t\tsimplification 2: \t5.582693972185599\n",
      "INFO: (CONTROLLER): we WILL be using the stabilizing controller with ||A-BK||_op=0.5834712386131287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression (ret) :\n",
      "||A||_op = 0.8092865943908691\n",
      "||B||_F = 5.75260591506958\n",
      "||A-BK||_op = 0.5834712386131287\n",
      "eig(A) = [0.17203853 0.17203853 0.08198473 0.0704478 ]\n",
      "svd(B) = [4.4987288 3.5852356]\n",
      "\n",
      "moments :\n",
      "||A||_op = 1.1270601749420166\n",
      "||B||_F = 2.048187494277954\n",
      "||A-BK||_op = 0.7723686695098877\n",
      "eig(A) = [1.0015647  0.51330096 0.21545346 0.09838992]\n",
      "svd(B) = [2.0478857  0.03514256]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████▌                            | 1000/2000 [02:03<2:27:45,  8.87s/it, control=[-0.01509719  0.01926161], cost=0.00921]INFO: (EXPERIMENT): reset at t=1000!\n",
      " 50%|██████████████████████████████████████▌                                      | 1001/2000 [02:03<2:02:04,  7.33s/it, control=[nan nan], cost=inf]ERROR: (EXPERIMENT): state None or cost inf diverged\n",
      " 50%|███████████████████████████████████████▌                                       | 1001/2000 [02:03<02:03,  8.09it/s, control=[nan nan], cost=inf]\n",
      "INFO: \n",
      "ERROR: (EXPERIMENT): none of the trials succeeded.\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "experiment = Experiment(name)\n",
    "stats = experiment(get_experiment_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044a38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save args and stats!  --  note that to save the args, we actually save the `get_args` function. we can print the \n",
    "#                           source code later to see the hyperparameters we chose\n",
    "# experiment.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8107c23",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We keep track of the useful information through `Stats` objects, which can `register()` a variable to keep track of (which it does via calls to `update()`) and which can be aggregated via `Stats.aggregate()` for mean and variance statistics. \n",
    "\n",
    "We define below a plotting arrangement that plots all the desired quantities from both the system and controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(experiment: Experiment):\n",
    "    assert experiment.stats is not None, 'cannot plot the results of an experiment that hasnt been run'\n",
    "    all_stats = experiment.stats\n",
    "    \n",
    "    # clear plot and calc nrows\n",
    "    plt.clf()\n",
    "    n = 4\n",
    "    nrows = n + (len(all_stats) + 1) // 2\n",
    "    fig, ax = plt.subplots(nrows, 2, figsize=(16, 6 * nrows))\n",
    "\n",
    "    # plot stats\n",
    "    for i, (method, stats) in enumerate(all_stats.items()):\n",
    "        if stats is None: \n",
    "            logging.warning('{} had no stats'.format(method))\n",
    "            continue\n",
    "            \n",
    "        stats.plot(ax[0, 0], 'lrs', label=method)\n",
    "        stats.plot(ax[1, 0], 'costs', label=method)\n",
    "        stats.plot(ax[1, 1], 'costs', label=method, plot_cummean=True)\n",
    "        stats.plot(ax[2, 0], 'avg train losses since reset', label=method)\n",
    "        stats.plot(ax[2, 1], 'avg val losses since reset', label=method)        \n",
    "        \n",
    "        stats.plot(ax[3, 0], 'states', label=method, plot_norm=True)  # norm of the \"state\"\n",
    "        from extravaganza.sysid import LOSS_WEIGHTS\n",
    "        for k in LOSS_WEIGHTS.keys(): stats.plot(ax[3, 1], k, label=k)  # various nn losses\n",
    "            \n",
    "        i_ax = ax[n + i // 2, i % 2]\n",
    "        stats.plot(ax[0, 1], 'disturbances', label=method, plot_norm=True)\n",
    "        idx = 1\n",
    "        stats.plot(i_ax, '-K @ state', label='-K @ state', plot_idx=idx)\n",
    "        stats.plot(i_ax, 'M \\cdot w', label='M \\cdot w', plot_idx=idx)\n",
    "        stats.plot(i_ax, 'M0', label='M0', plot_idx=idx)\n",
    "        i_ax.set_title('u decomp for {}'.format(method))\n",
    "        i_ax.legend()\n",
    "\n",
    "    # set titles and legends and limits and such\n",
    "    # (note: `ylim()` is so useful! because sometimes one thing blows up and then autoscale messes up all plots)\n",
    "    _ax = ax[0, 0]; _ax.set_title('learning rate'); _ax.legend()\n",
    "    _ax = ax[0, 1]; _ax.set_title('disturbances'); _ax.legend()\n",
    "    _ax = ax[1, 0]; _ax.set_title('instantaneous costs'); _ax.legend()\n",
    "    _ax = ax[1, 1]; _ax.set_title('avg costs'); _ax.legend(); ylim(_ax, 0, 10000)\n",
    "    _ax = ax[2, 0]; _ax.set_title('avg train losses since reset'); _ax.legend()\n",
    "    _ax = ax[2, 1]; _ax.set_title('avg val losses since reset'); _ax.legend()\n",
    "    _ax = ax[3, 0]; _ax.set_title('reconstructed states'); _ax.legend()\n",
    "    _ax = ax[3, 1]; _ax.set_title('nn losses'); _ax.legend()  \n",
    "    pass\n",
    "plot(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c615b",
   "metadata": {},
   "source": [
    "### Dynamic Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526926a",
   "metadata": {},
   "source": [
    "#### dynamic plot\n",
    "anim = render(experiment, 'lrs', 'train losses', sliderkey='lrs', save_path=None, duration=5)\n",
    "vid = anim.to_html5_video()\n",
    "HTML(vid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extravaganza",
   "language": "python",
   "name": "extravaganza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
